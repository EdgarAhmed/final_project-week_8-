# final_project-week_8

# Predictive Model for Overuse Injuries in Professional Football through Machine Learning

## Overview
This project represents the final undertaking of the Ironhack data analysis bootcamp, focusing on the development of a predictive model for overuse injuries in professional football using machine learning.

Types of Injuries in Football
In the realm of football injuries, they can be broadly categorized into two main groups:

Traumatic Injuries: Resulting from physical contact between players, such as collisions that lead to ankle sprains or anterior cruciate ligament (ACL) tears. These injuries are inherently challenging to prevent, often necessitating rule modifications in the game.

Overuse Injuries: Occurring without physical contact, these injuries are linked to prolonged player exposure without adequate rest. Examples include muscle fiber ruptures and tendon problems. Given their correlation with the concept of 'workload' (individual exposure time), preventive measures can be implemented.

## Motivation
Two primary motivations drove this project:

The estimated cost of injuries to a professional football team, averaging around Â£45 million (source).
Bridging the realms of sports, health, and massive data analysis.
Tools Used
The project involved data extraction through an API, with data loaded into MongoDB after the API call. Data cleaning and transformation were carried out using Visual Studio Code, leveraging libraries such as "pandas," "datetime," and "numpy." Tableau Public was employed for data visualization, and the project presentation was crafted using Canva.

## Challenges Faced, Lessons Learned, and Future Work
Unfortunately, due to time constraints, the machine learning process could not be completed. Issues arose from inaccurate information in the API data, discovered when cross-referenced with the official website of one of the clubs.

As a valuable lesson, relying on original sources is crucial, with third-party APIs being a secondary option. Future work aims to incorporate web scraping tools like "Selenium" to extract reliable data from official websites.

The envisioned model development hinged on obtaining accurate data, which was hindered in this instance.

Technologies Used
